{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9570495f-8f67-4249-ae41-bedf70185f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                driver         flag               team  car_number  \\\n",
      "0    Stoffel Vandoorne      Belgium            McLaren           2   \n",
      "1       Logan Sargeant          USA           Williams           2   \n",
      "2     Daniel Ricciardo    Australia                 RB           3   \n",
      "3          Max Chilton           UK           Marussia           4   \n",
      "4         Lando Norris           UK            McLaren           4   \n",
      "5     Sebastian Vettel      Germany       Aston Martin           5   \n",
      "6         Nico Rosberg      Germany           Mercedes           6   \n",
      "7      Nicholas Latifi       Canada           Williams           6   \n",
      "8       Kimi Raikkonen      Finland  Alfa Romeo Racing           7   \n",
      "9      Romain Grosjean       France               Haas           8   \n",
      "10     Marcus Ericsson      Sweeden             Sauber           9   \n",
      "11      Nikita Mazepin       Russia               Haas           9   \n",
      "12     Kamui Kobayashi        Japan           Caterham          10   \n",
      "13        Pierre Gasly       France             Alpine          10   \n",
      "14        Sergio Perez       Mexico    Red Bull Racing          11   \n",
      "15         Felipe Nasr       Brazil             Sauber          12   \n",
      "16    Pastor Maldonado    Venezuela              Lotus          13   \n",
      "17     Fernando Alonso        Spain       Aston Martin          14   \n",
      "18     Charles Leclerc       Monaco            Ferrari          16   \n",
      "19       Jules Bianchi       France           Marussia          17   \n",
      "20        Lance Stroll       Canada       Aston Martin          18   \n",
      "21        Felipe Massa       Brazil           Williams          19   \n",
      "22     Kevin Magnussen      Denmark               Haas          20   \n",
      "23   Esteban Gutierrez       Mexico               Haas          21   \n",
      "24       Nyck de Vries  Netherlands         AlphaTauri          21   \n",
      "25       Jenson Button           UK            McLaren          22   \n",
      "26        Yuki Tsunoda        Japan                 RB          22   \n",
      "27     Alexander Albon     Thailand           Williams          23   \n",
      "28         Zhou Guanyu        China             Sauber          24   \n",
      "29    Jean-Eric Vergne       France         Toro Rosso          25   \n",
      "30        Daniil Kvyat       Russia         AlphaTauri          26   \n",
      "31     Nico Hulkenberg      Germany               Haas          27   \n",
      "32        Will Stevens           UK           Marussia          28   \n",
      "33     Brendon Hartley  New Zealand         Toro Rosso          28   \n",
      "34       Jolyon Palmer           UK            Renault          30   \n",
      "35        Esteban Ocon       France             Alpine          31   \n",
      "36      Max Verstappen  Netherlands    Red Bull Racing          33   \n",
      "37     Sergey Sirotkin       Russia           Williams          35   \n",
      "38      Oliver Bearman           UK            Ferrari          38   \n",
      "39         Liam Lawson  New Zealand         AlphaTauri          40   \n",
      "40       Paul di Resta           UK           Williams          40   \n",
      "41      Lewis Hamilton           UK           Mercedes          44   \n",
      "42      Andre Lotterer      Germany           Caterham          45   \n",
      "43     Mick Schumacher      Germany               Haas          47   \n",
      "44   Pietro Fittipaldi       Brazil               Haas          51   \n",
      "45     Alexander Rossi          USA           Marussia          53   \n",
      "46        Carlos Sainz        Spain            Ferrari          55   \n",
      "47      George Russell           UK           Mercedes          63   \n",
      "48     Valtteri Bottas      Finland             Sauber          77   \n",
      "49       Oscar Piastri    Australia            McLaren          81   \n",
      "50        Rio Haryanto    Indonesia              Manor          88   \n",
      "51       Robert Kubica       Poland  Alfa Romeo Racing          88   \n",
      "52         Jack Aitken           UK           Williams          89   \n",
      "53     Pascal Wehrlein      Germany             Sauber          94   \n",
      "54       Roberto Merhi        Spain              Manor          98   \n",
      "55        Adrian Sutil      Germany             Sauber          99   \n",
      "56  Antonio Giovinazzi        Italy  Alfa Romeo Racing          99   \n",
      "\n",
      "    birth year  start year  wins  \n",
      "0         1992        2016     0  \n",
      "1         2000        2023     0  \n",
      "2         1989        2011     8  \n",
      "3         1991        2013     0  \n",
      "4         1999        2019     0  \n",
      "5         1987        2007    53  \n",
      "6         1985        2006    23  \n",
      "7         1995        2020     0  \n",
      "8         1979        2001    21  \n",
      "9         1986        2009     0  \n",
      "10        1990        2014     0  \n",
      "11        1999        2021     0  \n",
      "12        1986        2009     0  \n",
      "13        1996        2017     1  \n",
      "14        1990        2011     6  \n",
      "15        1992        2015     0  \n",
      "16        1985        2011     1  \n",
      "17        1981        2001    32  \n",
      "18        1997        2018     5  \n",
      "19        1989        2013     0  \n",
      "20        1998        2017     0  \n",
      "21        1981        2002    11  \n",
      "22        1992        2014     0  \n",
      "23        1991        2013     0  \n",
      "24        1995        2022     0  \n",
      "25        1980        2000    15  \n",
      "26        2000        2021     0  \n",
      "27        1996        2019     0  \n",
      "28        1999        2022     0  \n",
      "29        1990        2012     0  \n",
      "30        1994        2014     0  \n",
      "31        1987        2010     0  \n",
      "32        1991        2014     0  \n",
      "33        1989        2017     0  \n",
      "34        1991        2016     0  \n",
      "35        1996        2016     1  \n",
      "36        1997        2015    56  \n",
      "37        1995        2018     0  \n",
      "38        2005        2024     0  \n",
      "39        2002        2023     0  \n",
      "40        1986        2011     0  \n",
      "41        1985        2007   103  \n",
      "42        1981        2014     0  \n",
      "43        1999        2021     0  \n",
      "44        1996        2020     0  \n",
      "45        1991        2015     0  \n",
      "46        1994        2015     3  \n",
      "47        1998        2019     1  \n",
      "48        1989        2013    10  \n",
      "49        2001        2023     0  \n",
      "50        1993        2016     0  \n",
      "51        1984        2006     1  \n",
      "52        1995        2020     0  \n",
      "53        1994        2016     0  \n",
      "54        1991        2015     0  \n",
      "55        1983        2007     0  \n",
      "56        1993        2017     0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Replace 'your_file.xlsx' with the path to your Excel file\n",
    "df = pd.read_excel('driver_data_base.xlsx')\n",
    "\n",
    "# Now 'df' is a DataFrame containing the data from your Excel file\n",
    "print(df.head(100))  # Print the first 20 rows of the DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9de598a6-1406-4588-a0bb-e020eeb9e1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import gym\n",
    "from gym import spaces\n",
    "import pandas as pd\n",
    "\n",
    "class F1MysteryDriverEnv(gym.Env):\n",
    "    metadata = {'render.modes': ['human']}\n",
    "    \n",
    "    def __init__(self, df):\n",
    "        super(F1MysteryDriverEnv, self).__init__()\n",
    "        \n",
    "        self.df = df\n",
    "        self.action_space = spaces.Discrete(len(df['driver']))  # Drivers are unique\n",
    "        self.observation_space = spaces.Dict({\n",
    "            \"attempts\": spaces.Discrete(6),  # A max of 6 attempts\n",
    "            \"feedback\": spaces.MultiDiscrete([3] * 6)  # Feedback for each hint category\n",
    "        })\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.state = {\n",
    "            \"mystery_driver\": random.choice(self.df['driver']),\n",
    "            \"attempts\": 0,\n",
    "        }\n",
    "        self.state[\"mystery_driver_info\"] = self.df.loc[\n",
    "            self.df['driver'] == self.state[\"mystery_driver\"],\n",
    "            ['car_number', 'start year', 'birth year', 'flag', 'team', 'wins']\n",
    "        ].values[0]\n",
    "        \n",
    "        initial_observation = {\n",
    "            \"attempts\": self.state[\"attempts\"],\n",
    "            \"feedback\": np.zeros(6)  # Initial feedback is all zeros (no information)\n",
    "        }\n",
    "        return initial_observation\n",
    "\n",
    "    def step(self, action):\n",
    "        assert self.action_space.contains(action)\n",
    "        entered_driver = self.df['driver'].iloc[action]  # Map action to the driver name\n",
    "        reward = 0\n",
    "        done = False\n",
    "        info = {}\n",
    "        \n",
    "        # Initialize feedback with whatever default you find suitable, e.g., np.zeros(6)\n",
    "        feedback = np.zeros(6)\n",
    "        \n",
    "        if entered_driver == self.state[\"mystery_driver\"]:\n",
    "            reward = 10  # For choosing the correct driver\n",
    "            done = True\n",
    "            info[\"message\"] = f\"Correct! It is {self.state['mystery_driver_info']} YOU WIN!\"\n",
    "        else:\n",
    "            self.state[\"attempts\"] += 1\n",
    "            feedback = self.get_feedback(entered_driver)  # Generate feedback based on the driver\n",
    "            if self.state[\"attempts\"] < 6:\n",
    "                reward = -1  # Negative reward for incorrect guess\n",
    "            else:\n",
    "                # The feedback calculation is already done above, so we can remove it from here\n",
    "                reward = -10  # More substantial negative reward for losing the game\n",
    "                done = True\n",
    "                info[\"message\"] = \"Game Over. Reached maximum attempts.\"\n",
    "        \n",
    "        observation = {\n",
    "            \"attempts\": self.state[\"attempts\"],\n",
    "            \"feedback\": feedback\n",
    "        }\n",
    "\n",
    "        return observation, reward, done, info\n",
    "    \n",
    "    def get_feedback(self, entered_driver):\n",
    "        feedback = np.zeros(6)  # We have 6 pieces of feedback\n",
    "\n",
    "        # Number comparison\n",
    "        entered_driver_number = self.df.loc[self.df['driver'] == entered_driver, 'car_number'].values[0]\n",
    "        if entered_driver_number > self.state[\"mystery_driver_info\"][0]:\n",
    "            feedback[0] = -1\n",
    "        elif entered_driver_number < self.state[\"mystery_driver_info\"][0]:\n",
    "            feedback[0] = 1\n",
    "\n",
    "        # Birth year comparison\n",
    "        entered_driver_birth_year = self.df.loc[self.df['driver'] == entered_driver, 'birth year'].values[0]\n",
    "        if entered_driver_birth_year > self.state[\"mystery_driver_info\"][2]:\n",
    "            feedback[1] = -1\n",
    "        elif entered_driver_birth_year < self.state[\"mystery_driver_info\"][2]:\n",
    "            feedback[1] = 1\n",
    "\n",
    "        # Start year comparison\n",
    "        entered_driver_start_year = self.df.loc[self.df['driver'] == entered_driver, 'start year'].values[0]\n",
    "        if entered_driver_start_year > self.state[\"mystery_driver_info\"][1]:\n",
    "            feedback[2] = -1\n",
    "        elif entered_driver_start_year < self.state[\"mystery_driver_info\"][1]:\n",
    "            feedback[2] = 1\n",
    "\n",
    "        # Wins comparison\n",
    "        entered_driver_wins = self.df.loc[self.df['driver'] == entered_driver, 'wins'].values[0]\n",
    "        if entered_driver_wins > self.state[\"mystery_driver_info\"][5]:\n",
    "            feedback[3] = -1\n",
    "        elif entered_driver_wins < self.state[\"mystery_driver_info\"][5]:\n",
    "            feedback[3] = 1\n",
    "\n",
    "        # Flag comparison\n",
    "        entered_driver_flag = self.df.loc[self.df['driver'] == entered_driver, 'flag'].values[0]\n",
    "        feedback[4] = 0 if entered_driver_flag == self.state[\"mystery_driver_info\"][3] else 1\n",
    "\n",
    "        # Team comparison \n",
    "        entered_driver_team = self.df.loc[self.df['driver'] == entered_driver, 'team'].values[0]\n",
    "        if entered_driver_team == self.state[\"mystery_driver_info\"][4]:\n",
    "            feedback[5] = 0\n",
    "        else:\n",
    "            feedback[5] = 1\n",
    "        return feedback\n",
    "        \n",
    "    def render(self, mode='human'):\n",
    "        # You can print out game state, feedback, or any other user-friendly information\n",
    "        print(f\"Attempts: {self.state['attempts']}\")\n",
    "\n",
    "    def close(self):\n",
    "        # Perform any cleanup, if necessary\n",
    "        pass\n",
    "\n",
    "# A simple Q-learning agent class\n",
    "class QLearningAgent:\n",
    "    def __init__(self, action_space, state_space, learning_rate=0.1, discount_factor=0.99, exploration_rate=1.0, max_exploration_rate=1.0, min_exploration_rate=0.01, exploration_decay_rate=0.001):\n",
    "        self.action_space = action_space\n",
    "        self.state_space = state_space\n",
    "        self.learning_rate = learning_rate\n",
    "        self.discount_factor = discount_factor\n",
    "        self.exploration_rate = exploration_rate\n",
    "        self.max_exploration_rate = max_exploration_rate\n",
    "        self.min_exploration_rate = min_exploration_rate\n",
    "        self.exploration_decay_rate = exploration_decay_rate\n",
    "        self.q_table = np.zeros((state_space, action_space.n))\n",
    "\n",
    "    # QLearningAgent class - inside the class definition\n",
    "    def get_state_as_int(self, observation):\n",
    "        # Since feedback can be -1, 0, 1, first map these values to 0, 1, 2 for non-negative encoding\n",
    "        mapped_feedback = observation['feedback'] + 1  # Shift from [-1, 0, 1] to [0, 1, 2]\n",
    "        base = 3  # Now we use base 3 because we have three possible values: 0, 1, 2\n",
    "        \n",
    "        feedback_int = 0\n",
    "        for i, val in enumerate(mapped_feedback):\n",
    "            feedback_int *= base\n",
    "            feedback_int += val\n",
    "        \n",
    "        # Calculate the state by combining attempts and feedback values\n",
    "        state_int = observation['attempts'] * (base ** len(mapped_feedback)) + feedback_int\n",
    "        return int(state_int)\n",
    "        \n",
    "    def choose_action(self, observation):\n",
    "        state = self.get_state_as_int(observation)\n",
    "        exploration_rate_threshold = np.random.uniform(0, 1)\n",
    "        if exploration_rate_threshold > self.exploration_rate:\n",
    "            action = np.argmax(self.q_table[state])  # Exploit the best known value\n",
    "        else:\n",
    "            action = self.action_space.sample()  # Explore action space\n",
    "        return action\n",
    "\n",
    "    def learn(self, state, action, reward, next_state, done):\n",
    "        old_value = self.q_table[state, action]\n",
    "        next_max = np.max(self.q_table[next_state])\n",
    "        \n",
    "        new_value = (1 - self.learning_rate) * old_value + self.learning_rate * (reward + self.discount_factor * next_max)\n",
    "        self.q_table[state, action] = new_value\n",
    "        \n",
    "        if done:\n",
    "            self.exploration_rate = max(self.min_exploration_rate, self.exploration_rate * self.exploration_rate_decay)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5aa40cda-e746-4c72-b06d-e00c1a1188c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = F1MysteryDriverEnv(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c476e2d3-3480-4256-b5b7-fef1f529724a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "729"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_feedback_options = 3 ** len(env.observation_space.spaces['feedback'].nvec)\n",
    "num_feedback_options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43f8ab93-9d20-4589-9b51-0081b7c62e56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_attempts = env.observation_space.spaces['attempts'].n\n",
    "num_attempts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1fad936f-c9ce-4b91-bba7-9037365990f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4374"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_state_space_size = num_attempts * num_feedback_options\n",
    "total_state_space_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c84a1ec-36c2-485e-af77-1d46a56a09cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = QLearningAgent(env.action_space, total_state_space_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c85e361-bd3d-4ce4-84d4-47d029cce3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_episodes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91546a28-a4f1-465c-b7a3-99b018b5461f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "364.0\n"
     ]
    }
   ],
   "source": [
    "for episode in range(number_of_episodes):\n",
    "    observation = env.reset()\n",
    "    state = agent.get_state_as_int(observation)\n",
    "    print(state)\n",
    "    break\n",
    "    total_reward = 0\n",
    "    done = False\n",
    "    steps = 0\n",
    "    \n",
    "    while not done and steps < num_attempts:\n",
    "        action = agent.choose_action(observation)\n",
    "        next_observation, reward, done, info = env.step(action)\n",
    "        next_state = agent.get_state_as_int(next_observation)\n",
    "        agent.learn(state, action, reward, next_state, done)\n",
    "\n",
    "        state = next_state\n",
    "        observation = next_observation\n",
    "        total_reward += reward\n",
    "        steps += 1\n",
    "\n",
    "    print(f\"Episode {episode + 1} finished with total reward: {total_reward}\")\n",
    "\n",
    "    # Adjust the exploration rate\n",
    "    agent.exploration_rate = max(agent.min_exploration_rate, agent.exploration_rate * np.exp(-agent.exploration_decay_rate*episode))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6de739a-caf6-43a2-b5da-fc3766b6acf8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
